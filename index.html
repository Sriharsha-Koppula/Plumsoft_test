from fastapi import FastAPI
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import re

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)

# Load models
embed_model = SentenceTransformer("all-MiniLM-L6-v2")
tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.1")
model = AutoModelForCausalLM.from_pretrained("mistralai/Mistral-7B-Instruct-v0.1")
generator = pipeline("text-generation", model=model, tokenizer=tokenizer)

# Load your company data
with open("company_data.txt", "r") as f:
    docs = f.read().split("\n")
doc_embeddings = embed_model.encode(docs)

class Prompt(BaseModel):
    query: str

@app.post("/ask")
def ask(prompt: Prompt):
    query_embedding = embed_model.encode([prompt.query])
    similarities = cosine_similarity(query_embedding, doc_embeddings)[0]
    top_idx = similarities.argsort()[-2:][::-1]
    context = "\n".join([docs[i] for i in top_idx])

    final_prompt = (
        f"Use the following context to answer the question:\n{context}\n\n"
        f"Answer the user's question conversationally and informatively without repeating the question:\n"
        f"{prompt.query}"
    )

    output = generator(final_prompt, max_new_tokens=200)[0]["generated_text"]

    # âœ¨ Clean the output - remove everything before the first capital-letter sentence
    match = re.search(r"[A-Z][^.?!]*[.?!]", output)
    cleaned_output = output[match.start():].strip() if match else output.strip()

    return {"response": cleaned_output}
